# -*- coding: utf-8 -*-
"""crop_yeild.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VODFRPbr2NS_rt6Xa2u13uLNLr5p1wp0
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

#Import the dataset which is csv file

dataset=pd.read_csv("/content/maharashtra_Rice_CropR1.csv")

#View the dataset
dataset

#Shape of dataset : cotains 926 rows and 10 columns
dataset.shape

"""**pre processing stage**"""

dataset=dataset.drop(['State_Name','Crop'],axis=1)

dataset

dataset.info()

print(dataset['District_Name'].unique())

"""**visualizing dataset**"""

plt.figure(figsize=(17,6), dpi = 100)
chart=sns.countplot(x='District_Name',data=dataset,palette='Set1')
plt.xlabel('District_Name')
chart.set_xticklabels(chart.get_xticklabels(), rotation=45,horizontalalignment='right',fontweight='light',
    fontsize='x-large')
plt.title("Record Count in Maharastra per Year from 1997 to 2019", fontsize=17)
plt.tight_layout()

by_year = dataset.groupby('Crop_Year')['Production'].sum()
# Plotting the bars

ax = by_year.plot(kind='bar', figsize=(15,5), color="indigo", fontsize=13)
ax.set_alpha(0.8)
ax.set_title("Overall Production in Maharastra per Year from 1997 to 2019", fontsize=16)
ax.set_ylabel("Production", fontsize=15)
plt.show()

by_year = dataset.groupby('Crop_Year')['Rainfall'].mean()
# Plotting the bars

ax = by_year.plot(kind='bar', figsize=(15,5), color="green", fontsize=13)
ax.set_alpha(0.8)
ax.set_title("Rainfall in Maharastra per Year from 1997 to 2019", fontsize=16)
ax.set_ylabel("Average Rainfall", fontsize=15)
plt.show()

by_year = dataset.groupby('Crop_Year')['MaxTemp'].mean()
# Plotting the bars

ax = by_year.plot(kind='bar', figsize=(15,4), color="skyblue", fontsize=13)
ax.set_alpha(0.8)
ax.set_title("Max Temperature in Maharastra per Year from 1997 to 2019", fontsize=16)
ax.set_ylabel("Maximum Temperature", fontsize=15)
plt.show()

#Creating the correlation matrix for the features
#Creating the correlation matrix for the features
#corr_matrix

#converting the dataframe to numpy array
data=dataset.iloc[:,:].values

data

#Converting categorical data like District_Name and Season into numeric
#Encoding categorical data
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# Label Encoding the 'District_Name' and 'Season' columns
labelencoder_0 = LabelEncoder()
data[:, 0] = labelencoder_0.fit_transform(data[:, 0])

labelencoder_2 = LabelEncoder()
data[:, 2] = labelencoder_2.fit_transform(data[:, 2])

# OneHotEncoder: Use ColumnTransformer to one-hot encode the first column (District_Name)
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

# Use ColumnTransformer to apply OneHotEncoder on the first column (District_Name)
onehotencoder = ColumnTransformer(transformers=[('encoder', OneHotEncoder(handle_unknown='ignore'), [0])],
                                  remainder='passthrough')

# Transform the data using OneHotEncoder
data = onehotencoder.fit_transform(data)

# Converting the sparse matrix to a dense array if necessary
data = data.toarray()

# Continue with your model training process

data

data.shape

"""**Spliting the data for training and testing data**"""

X=data[:,:-1]
y=data[:,-1]

#Creating Train Test Split
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=101)

X_train,y_train=np.array(X_train),np.array(y_train)

"""**Creating a  model**"""

from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score

#Decision Tree Regressor
from sklearn.tree import DecisionTreeRegressor

DTregressor=DecisionTreeRegressor()
DTregressor.fit(X_train,y_train)

y_pred_DT=DTregressor.predict(X_test)

DecisionTreeRegressor=pd.DataFrame({'Actual':y_test,'Predicted':y_pred_DT})
DecisionTreeRegressor

print('Mean Absolute Error:',mean_absolute_error(y_test,y_pred_DT))
print('Mean squared Error:',mean_squared_error(y_test,y_pred_DT))
print('Root Mean Squared Error:',np.sqrt(mean_squared_error(y_test,y_pred_DT)))
#print('R2_Score:',r2_score(y_test, y_pred_DT))

decision_r2_score= r2_score(y_test, y_pred_DT)
print("Accuracy = ",decision_r2_score*100,"%")

# Visualising the results
plt.figure(figsize=(15,4))
plt.plot(y_test, color = 'red', label = 'Real Productivity')
plt.plot(y_pred_DT, color = 'blue', label = 'Predicted productivity')
plt.title('Decision Tree Regressor Prediction',fontsize=15)
plt.xlabel('Districts',fontsize=15)
plt.ylabel('Production',fontsize=15)
plt.legend()
plt.show()

"""**model-2 K-nearest neighbour**"""

#Nearest Neighbour=2
from sklearn.neighbors import KNeighborsRegressor
neigh_2 = KNeighborsRegressor(n_neighbors=3)
neigh_2.fit(X_train, y_train)

y_pred_kn_2=neigh_2.predict(X_test)

KNN_2=pd.DataFrame({'Actual':y_test,'Predicted':y_pred_kn_2})
KNN_2

print('Mean Absolute Error:',mean_absolute_error(y_test,y_pred_kn_2))
print('Mean squared Error:',mean_squared_error(y_test,y_pred_kn_2))
print('Root Mean Squared Error:',np.sqrt(mean_squared_error(y_test,y_pred_kn_2)))
#print('R2_Score:',r2_score(y_test, y_pred_kn_2))

knn2_r2_score= r2_score(y_test, y_pred_kn_2)
print("Accuracy =",knn2_r2_score*100,"%")

#Visualising the results
plt.figure(figsize=(15,4))
plt.plot(y_test, color = 'red', label = 'Real Productivity')
plt.plot(y_pred_kn_2, color = 'blue', label = 'Predicted productivity')
plt.title(' KNeighbour Regressor Prediction',fontsize=15)
plt.xlabel('Districts',fontsize=15)
plt.ylabel('Production',fontsize=15)
plt.legend()
plt.show()

"""**RandomForest Regressor**"""

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators = 1000, random_state = 46)
rf.fit(X_train, y_train);

rf_pred=rf.predict(X_test)
print('Mean squared Error:',mean_squared_error(y_test,rf_pred))
print('Root Mean Squared Error:',np.sqrt(mean_squared_error(y_test,rf_pred)))
#print('R2_Score:',r2_score(y_test,rf_pred))

randomforest_r2_score=r2_score(y_test,rf_pred)
print("Accuracy = ",randomforest_r2_score*100,"%")

#Visualising the results
plt.figure(figsize=(15,4))
plt.plot(y_test, color = 'red', label = 'Real Productivity')
plt.plot(rf_pred, color = 'blue', label = 'Predicted productivity')
plt.title(' Random Forest Regressor Prediction',fontsize=15)
plt.xlabel('Districts',fontsize=15)
plt.ylabel('Production',fontsize=15)
plt.legend()
plt.show()

Regressors=['RandomForest','DesicionTree','KNeighbour']

R2Score=[randomforest_r2_score,decision_r2_score,knn2_r2_score]

plt.figure(figsize=(15,5))
plt.plot(Regressors,R2Score, color = 'Blue')

plt.title('Comparision between different Regressors',fontsize=15)
plt.xlabel('Regressors',fontsize=15)
plt.ylabel('Accuracy Values',fontsize=15)
plt.legend()
plt.show()

import matplotlib.pyplot as plt
R2Score = [randomforest_r2_score, decision_r2_score, knn2_r2_score]

# Convert R² Scores into percentages (accuracy)
accuracy_scores = [score * 100 for score in R2Score]
models = ['Random Forest', 'Decision Tree', 'KNN']
plt.figure(figsize=(8, 5))
plt.bar(models, accuracy_scores, color=['blue', 'green', 'red'])
plt.xlabel('Models')
plt.ylabel('Accuracy (%)')
plt.title('Model Accuracy Comparison (R² Score as Accuracy)')
plt.ylim(0, 100)
plt.show()